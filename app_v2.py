import streamlit as st
import openai
import PyPDF2
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
import json
import base64
import numpy as np
from io import BytesIO
from sklearn.preprocessing import MinMaxScaler
import os, requests

# ğŸ“Œ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ì±„ìš© ì í•©ë„ ë¶„ì„ê¸°", layout="wide")
st.title("âœ¨ GPT ê¸°ë°˜ ì±„ìš© ì í•©ë„ ë¶„ì„ê¸°")

# ğŸ” API ì…ë ¥
st.sidebar.title("ğŸ” GPT API Key")
api_key = st.sidebar.text_input("OpenAI API Key ì…ë ¥", type="password")
if not api_key:
    st.warning("ğŸ”‘ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()
client = openai.OpenAI(api_key=api_key)

# ğŸ“Œ JD + ê°€ì¤‘ì¹˜
st.sidebar.subheader("ğŸ“Œ JD ì…ë ¥")
jd_input = st.sidebar.text_area("JD ë˜ëŠ” ì¸ì‚¬ë‹´ë‹¹ì ë©”ëª¨")
st.sidebar.subheader("âš–ï¸ JD ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜")
weights = {
    "í•µì‹¬ ê²½í—˜ê³¼ í‚¤ì›Œë“œ": st.sidebar.slider("ê²½í—˜ í‚¤ì›Œë“œ ì¤‘ìš”ë„", 1, 5, 3),
    "ê°•ì ": st.sidebar.slider("ê°•ì  í•­ëª© ì¤‘ìš”ë„", 1, 5, 3),
    "ìš°ë ¤ì‚¬í•­": st.sidebar.slider("ìš°ë ¤ì‚¬í•­ ë¯¼ê°ë„ (ê°ì )", 1, 5, 3),
    "ë¯¸ë˜ ì ì¬ì—­ëŸ‰": st.sidebar.slider("ë¯¸ë˜ ì ì¬ë ¥ ì¤‘ìš”ë„", 1, 5, 2),
}

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_files = st.file_uploader("ğŸ“„ ìê¸°ì†Œê°œì„œ ì—…ë¡œë“œ (PDF ë˜ëŠ” TXT)", type=["pdf", "txt"], accept_multiple_files=True)

def extract_text(file):
    if file.type == "application/pdf":
        reader = PyPDF2.PdfReader(file)
        return "\n".join([page.extract_text() for page in reader.pages])
    return file.read().decode("utf-8")

def to_base64(fig):
    buf = BytesIO()
    fig.savefig(buf, format="png", bbox_inches='tight')
    return base64.b64encode(buf.getvalue()).decode()

# âœ… WordCloud (í°íŠ¸ ìë™ ë‹¤ìš´ë¡œë“œ)
def generate_wordcloud(text):
    font_path = "/tmp/NanumGothic.ttf"
    if not os.path.exists(font_path):
        url = "https://github.com/naver/nanumfont/releases/download/VER2.5/NanumGothic.ttf"
        r = requests.get(url)
        with open(font_path, "wb") as f:
            f.write(r.content)
    wc = WordCloud(font_path=font_path, background_color="white", width=600, height=300).generate(text)
    fig, ax = plt.subplots()
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")
    return to_base64(fig)

# âœ… Radar Chart
def generate_radar_chart(labels, values):
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=values, theta=labels, fill='toself'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=False)
    buf = BytesIO()
    fig.write_image(buf, format="png", width=500, height=400)
    return base64.b64encode(buf.getvalue()).decode()

# âœ… ì¢…í•© ìš”ì•½ ì‹œê°í™”
def generate_summary_charts(results):
    names = [r["íŒŒì¼ëª…"] for r in results]
    scores = [r["ì „ë°˜ì  ì í•©ë„ ì ìˆ˜"] for r in results]
    strengths = [len(r["ê°•ì "]) for r in results]
    weaknesses = [len(r["ìš°ë ¤ì‚¬í•­"]) for r in results]

    # íˆíŠ¸ë§µ
    df = pd.DataFrame({
        "íŒŒì¼ëª…": names,
        "ì í•©ë„": scores,
        "ê°•ì ": strengths,
        "ìš°ë ¤ì‚¬í•­": weaknesses
    }).set_index("íŒŒì¼ëª…")
    normed = MinMaxScaler().fit_transform(df)
    fig1, ax1 = plt.subplots()
    sns.heatmap(normed, annot=df.values, fmt=".0f", cmap="YlGnBu", xticklabels=df.columns, yticklabels=names, ax=ax1)
    heatmap_b64 = to_base64(fig1)

    # í‰ê·  ì—­ëŸ‰ ì ìˆ˜
    all_scores = {}
    for r in results:
        for k, v in r["ì—­ëŸ‰ë³„ í‰ê°€ ì½”ë©˜íŠ¸"].items():
            score = 5 if "ìš°ìˆ˜" in v or "ë†’ìŒ" in v else 3 if "ë³´í†µ" in v else 1
            all_scores[k] = all_scores.get(k, 0) + score
    avg_scores = {k: round(v / len(results), 2) for k, v in all_scores.items()}
    fig2, ax2 = plt.subplots()
    sns.barplot(x=list(avg_scores.keys()), y=list(avg_scores.values()), ax=ax2)
    avg_b64 = to_base64(fig2)

    return heatmap_b64, avg_b64

# âœ… GPT ë¶„ì„ ì‹¤í–‰
results = []
if st.button("ğŸ“Š ì í•©ë„ ë¶„ì„ ì‹¤í–‰") and uploaded_files and jd_input:
    for file in uploaded_files:
        text = extract_text(file)
        prompt = f"""
        JD ë˜ëŠ” ê¸°ëŒ€ì‚¬í•­: {jd_input}

        ìê¸°ì†Œê°œì„œ:
        {text}

        ë‹¤ìŒ í•­ëª©ì— ëŒ€í•´ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì¤˜:
        {{
        "í•µì‹¬ ê²½í—˜ê³¼ í‚¤ì›Œë“œ": [...],
        "ì „ë°˜ì  ì í•©ë„ ì ìˆ˜": 0~100 ì •ìˆ˜,
        "ê°•ì ": [...],
        "ìš°ë ¤ì‚¬í•­": [...],
        "ì¢…í•© ì˜ê²¬ ìš”ì•½": "...",
        "ì¶”ì²œ ì—¬ë¶€": "...",
        "ë¯¸ë˜ ì ì¬ì—­ëŸ‰ ë˜ëŠ” ì„±ì¥ ê°€ëŠ¥ì„±": "...",
        "ì—­ëŸ‰ë³„ í‰ê°€ ì½”ë©˜íŠ¸": {{
            "ë¬¸ì œ í•´ê²°ë ¥": "...",
            "ë°ì´í„° í™œìš©ë ¥": "...",
            "í˜‘ì—…/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": "...",
            "í•™ìŠµ ë° ì„±ì¥ì˜ì§€": "..."
        }}
        }}
        """
        try:
            res = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            content = res.choices[0].message.content
            parsed = json.loads(content[content.find("{"):content.rfind("}") + 1])
            parsed["íŒŒì¼ëª…"] = file.name
            results.append(parsed)
        except Exception as e:
            st.error(f"{file.name} ë¶„ì„ ì‹¤íŒ¨: {e}")

# âœ… HTML ë³´ê³ ì„œ ë Œë”ë§
if results:
    st.success("âœ… ë¶„ì„ ì™„ë£Œ")
    st.markdown("## ğŸ“‘ ë¶„ì„ ë¦¬í¬íŠ¸ (PDF ì €ì¥ ê°€ëŠ¥)")

    html = "<html><body><h1>ì±„ìš© ì í•©ë„ ë¶„ì„ ë¦¬í¬íŠ¸</h1>"
    for r in results:
        radar_labels = list(r["ì—­ëŸ‰ë³„ í‰ê°€ ì½”ë©˜íŠ¸"].keys())
        radar_values = [5 if "ìš°ìˆ˜" in v or "ë†’ìŒ" in v else 3 if "ë³´í†µ" in v else 1 for v in r["ì—­ëŸ‰ë³„ í‰ê°€ ì½”ë©˜íŠ¸"].values()]
        wordcloud_b64 = generate_wordcloud(" ".join(r["í•µì‹¬ ê²½í—˜ê³¼ í‚¤ì›Œë“œ"]))
        radar_b64 = generate_radar_chart(radar_labels, radar_values)

        html += f"<h2>{r['íŒŒì¼ëª…']}</h2>"
        html += f"<p><b>ì í•©ë„ ì ìˆ˜:</b> {r['ì „ë°˜ì  ì í•©ë„ ì ìˆ˜']} | <b>ì¶”ì²œ:</b> {r['ì¶”ì²œ ì—¬ë¶€']}</p>"
        html += f"<p><b>ë¯¸ë˜ ì ì¬ì—­ëŸ‰:</b> {r['ë¯¸ë˜ ì ì¬ì—­ëŸ‰ ë˜ëŠ” ì„±ì¥ ê°€ëŠ¥ì„±']}</p>"
        html += "<h4>ğŸ“Œ í•µì‹¬ ê²½í—˜ ë° í‚¤ì›Œë“œ</h4><ul>" + "".join(f"<li>{kw}</li>" for kw in r["í•µì‹¬ ê²½í—˜ê³¼ í‚¤ì›Œë“œ"]) + "</ul>"
        html += f"<img src='data:image/png;base64,{wordcloud_b64}' width='600'/>"
        html += "<h4>ğŸ’ª ê°•ì </h4><ul>" + "".join(f"<li>{s}</li>" for s in r["ê°•ì "]) + "</ul>"
        html += "<h4>âš ï¸ ìš°ë ¤ì‚¬í•­</h4><ul>" + "".join(f"<li>{w}</li>" for w in r["ìš°ë ¤ì‚¬í•­"]) + "</ul>"
        html += "<h4>ğŸ§  ì—­ëŸ‰ë³„ í‰ê°€</h4><ul>" + "".join(f"<li><b>{k}</b>: {v}</li>" for k, v in r["ì—­ëŸ‰ë³„ í‰ê°€ ì½”ë©˜íŠ¸"].items()) + "</ul>"
        html += f"<img src='data:image/png;base64,{radar_b64}' width='500'/>"
        html += f"<h4>ğŸ“ ì¢…í•© ì˜ê²¬</h4><p>{r['ì¢…í•© ì˜ê²¬ ìš”ì•½']}</p><hr>"

    heatmap_b64, avg_b64 = generate_summary_charts(results)
    html += "<h2>ğŸ“Š ì „ì²´ ì§€ì›ì ì¢…í•© ë¶„ì„</h2>"
    html += f"<h4>ì§€ì›ìë³„ ì§€í‘œ íˆíŠ¸ë§µ</h4><img src='data:image/png;base64,{heatmap_b64}' width='700'/>"
    html += f"<h4>ì—­ëŸ‰ í‰ê·  ì ìˆ˜</h4><img src='data:image/png;base64,{avg_b64}' width='600'/>"
    html += "</body></html>"

    st.components.v1.html(html, height=2200, scrolling=True)
    st.info("ğŸ’¾ PDF ì €ì¥: ë¸Œë¼ìš°ì €ì—ì„œ Ctrl+P ë˜ëŠ” âŒ˜+Pë¥¼ ëˆŒëŸ¬ 'PDFë¡œ ì €ì¥' ì„ íƒ")
